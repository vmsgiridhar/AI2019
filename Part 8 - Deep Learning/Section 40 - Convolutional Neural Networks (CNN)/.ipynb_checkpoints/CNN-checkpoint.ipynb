{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Problem using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x63c1c6080>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the different layers to the NN now. - Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(filters=32, kernel_size=[3,3], input_shape=(64, 64, 3), activation='relu'))\n",
    "# input_shape is 3D, 64 * 64 images. Input_shape is different in Theano and Tensorflow. Check before use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Pooling - Step 2\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are adding another Convolutional layer to improve the test set accuracy and also thus reducing the over fitting\n",
    "# Also the input to this 2nd Convolution layer will be max pooled feature maps from the above step.\n",
    "classifier.add(Convolution2D(filters=32, kernel_size=[3,3], activation='relu'))\n",
    "# We will add Max Pooling on the added Convolutional layer again.\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening - Converting Pooled Feature Maps to Vectors - Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full connection - Adding Convulutional NN to Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding layers\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "# Adding the output layer.\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Classifier\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Fitting CNN to the Images Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image augmentation - technique to reduce overfitting.(Good results on Training set and bad results on Testing set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 1470s 184ms/step - loss: 0.3896 - accuracy: 0.8164 - val_loss: 0.8017 - val_accuracy: 0.7910\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1353s 169ms/step - loss: 0.1531 - accuracy: 0.9383 - val_loss: 1.0712 - val_accuracy: 0.8063\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1296s 162ms/step - loss: 0.0755 - accuracy: 0.9719 - val_loss: 0.4190 - val_accuracy: 0.8061\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1217s 152ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 1.3801 - val_accuracy: 0.8161\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1230s 154ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 1.1323 - val_accuracy: 0.7996\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1322s 165ms/step - loss: 0.0323 - accuracy: 0.9890 - val_loss: 3.4836 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1313s 164ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.5650 - val_accuracy: 0.7993\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1352s 169ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 1.3513 - val_accuracy: 0.8035\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1275s 159ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 1.1457 - val_accuracy: 0.8095\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1226s 153ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 3.2709 - val_accuracy: 0.7919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x639fd3f98>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# converting all pixels to 0s and 1s - Training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# converting all pixels to 0s and 1s - Test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# training set image extraction for learning\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# testing set image extraction for learning\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "classifier.fit(\n",
    "        training_set,\n",
    "        steps_per_epoch=8000,\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After 10 epochs Accuracy of Training set is 99.22 and the Test accuracy is 76.58. The difference is actually huge close to 22% nearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try reducing the difference between them.\n",
    "\n",
    "# Adding a new Convolutional layer will improve the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation accuracy: 79.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
