{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73721.615600</td>\n",
       "      <td>121344.639600</td>\n",
       "      <td>211025.097800</td>\n",
       "      <td>112012.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45902.256482</td>\n",
       "      <td>28017.802755</td>\n",
       "      <td>122290.310726</td>\n",
       "      <td>40306.180338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>51283.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14681.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39936.370000</td>\n",
       "      <td>103730.875000</td>\n",
       "      <td>129300.132500</td>\n",
       "      <td>90138.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73051.080000</td>\n",
       "      <td>122699.795000</td>\n",
       "      <td>212716.240000</td>\n",
       "      <td>107978.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101602.800000</td>\n",
       "      <td>144842.180000</td>\n",
       "      <td>299469.085000</td>\n",
       "      <td>139765.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>165349.200000</td>\n",
       "      <td>182645.560000</td>\n",
       "      <td>471784.100000</td>\n",
       "      <td>192261.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           R&D Spend  Administration  Marketing Spend         Profit\n",
       "count      50.000000       50.000000        50.000000      50.000000\n",
       "mean    73721.615600   121344.639600    211025.097800  112012.639200\n",
       "std     45902.256482    28017.802755    122290.310726   40306.180338\n",
       "min         0.000000    51283.140000         0.000000   14681.400000\n",
       "25%     39936.370000   103730.875000    129300.132500   90138.902500\n",
       "50%     73051.080000   122699.795000    212716.240000  107978.190000\n",
       "75%    101602.800000   144842.180000    299469.085000  139765.977500\n",
       "max    165349.200000   182645.560000    471784.100000  192261.830000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# observations State is a categorical variable here\n",
    "# We should be using Label encoder and one-hot-encoder here in that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[165349.2, 136897.8, 471784.1, 'New York'],\n",
       "        [162597.7, 151377.59, 443898.53, 'California'],\n",
       "        [153441.51, 101145.55, 407934.54, 'Florida'],\n",
       "        [144372.41, 118671.85, 383199.62, 'New York'],\n",
       "        [142107.34, 91391.77, 366168.42, 'Florida'],\n",
       "        [131876.9, 99814.71, 362861.36, 'New York'],\n",
       "        [134615.46, 147198.87, 127716.82, 'California'],\n",
       "        [130298.13, 145530.06, 323876.68, 'Florida'],\n",
       "        [120542.52, 148718.95, 311613.29, 'New York'],\n",
       "        [123334.88, 108679.17, 304981.62, 'California'],\n",
       "        [101913.08, 110594.11, 229160.95, 'Florida'],\n",
       "        [100671.96, 91790.61, 249744.55, 'California'],\n",
       "        [93863.75, 127320.38, 249839.44, 'Florida'],\n",
       "        [91992.39, 135495.07, 252664.93, 'California'],\n",
       "        [119943.24, 156547.42, 256512.92, 'Florida'],\n",
       "        [114523.61, 122616.84, 261776.23, 'New York'],\n",
       "        [78013.11, 121597.55, 264346.06, 'California'],\n",
       "        [94657.16, 145077.58, 282574.31, 'New York'],\n",
       "        [91749.16, 114175.79, 294919.57, 'Florida'],\n",
       "        [86419.7, 153514.11, 0.0, 'New York'],\n",
       "        [76253.86, 113867.3, 298664.47, 'California'],\n",
       "        [78389.47, 153773.43, 299737.29, 'New York'],\n",
       "        [73994.56, 122782.75, 303319.26, 'Florida'],\n",
       "        [67532.53, 105751.03, 304768.73, 'Florida'],\n",
       "        [77044.01, 99281.34, 140574.81, 'New York'],\n",
       "        [64664.71, 139553.16, 137962.62, 'California'],\n",
       "        [75328.87, 144135.98, 134050.07, 'Florida'],\n",
       "        [72107.6, 127864.55, 353183.81, 'New York'],\n",
       "        [66051.52, 182645.56, 118148.2, 'Florida'],\n",
       "        [65605.48, 153032.06, 107138.38, 'New York'],\n",
       "        [61994.48, 115641.28, 91131.24, 'Florida'],\n",
       "        [61136.38, 152701.92, 88218.23, 'New York'],\n",
       "        [63408.86, 129219.61, 46085.25, 'California'],\n",
       "        [55493.95, 103057.49, 214634.81, 'Florida'],\n",
       "        [46426.07, 157693.92, 210797.67, 'California'],\n",
       "        [46014.02, 85047.44, 205517.64, 'New York'],\n",
       "        [28663.76, 127056.21, 201126.82, 'Florida'],\n",
       "        [44069.95, 51283.14, 197029.42, 'California'],\n",
       "        [20229.59, 65947.93, 185265.1, 'New York'],\n",
       "        [38558.51, 82982.09, 174999.3, 'California'],\n",
       "        [28754.33, 118546.05, 172795.67, 'California'],\n",
       "        [27892.92, 84710.77, 164470.71, 'Florida'],\n",
       "        [23640.93, 96189.63, 148001.11, 'California'],\n",
       "        [15505.73, 127382.3, 35534.17, 'New York'],\n",
       "        [22177.74, 154806.14, 28334.72, 'California'],\n",
       "        [1000.23, 124153.04, 1903.93, 'New York'],\n",
       "        [1315.46, 115816.21, 297114.46, 'Florida'],\n",
       "        [0.0, 135426.92, 0.0, 'California'],\n",
       "        [542.05, 51743.15, 0.0, 'New York'],\n",
       "        [0.0, 116983.8, 45173.06, 'California']], dtype=object),\n",
       " array([ 192261.83,  191792.06,  191050.39,  182901.99,  166187.94,\n",
       "         156991.12,  156122.51,  155752.6 ,  152211.77,  149759.96,\n",
       "         146121.95,  144259.4 ,  141585.52,  134307.35,  132602.65,\n",
       "         129917.04,  126992.93,  125370.37,  124266.9 ,  122776.86,\n",
       "         118474.03,  111313.02,  110352.25,  108733.99,  108552.04,\n",
       "         107404.34,  105733.54,  105008.31,  103282.38,  101004.64,\n",
       "          99937.59,   97483.56,   97427.84,   96778.92,   96712.8 ,\n",
       "          96479.51,   90708.19,   89949.14,   81229.06,   81005.76,\n",
       "          78239.91,   77798.83,   71498.49,   69758.98,   65200.33,\n",
       "          64926.08,   49490.75,   42559.73,   35673.41,   14681.4 ]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data into features and target\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,4].values\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have state consisting of Categorical variables.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X= LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,3] = labelencoder_X.fit_transform(X[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 2],\n",
       "       [162597.7, 151377.59, 443898.53, 0],\n",
       "       [153441.51, 101145.55, 407934.54, 1],\n",
       "       [144372.41, 118671.85, 383199.62, 2],\n",
       "       [142107.34, 91391.77, 366168.42, 1],\n",
       "       [131876.9, 99814.71, 362861.36, 2],\n",
       "       [134615.46, 147198.87, 127716.82, 0],\n",
       "       [130298.13, 145530.06, 323876.68, 1],\n",
       "       [120542.52, 148718.95, 311613.29, 2],\n",
       "       [123334.88, 108679.17, 304981.62, 0],\n",
       "       [101913.08, 110594.11, 229160.95, 1],\n",
       "       [100671.96, 91790.61, 249744.55, 0],\n",
       "       [93863.75, 127320.38, 249839.44, 1],\n",
       "       [91992.39, 135495.07, 252664.93, 0],\n",
       "       [119943.24, 156547.42, 256512.92, 1],\n",
       "       [114523.61, 122616.84, 261776.23, 2],\n",
       "       [78013.11, 121597.55, 264346.06, 0],\n",
       "       [94657.16, 145077.58, 282574.31, 2],\n",
       "       [91749.16, 114175.79, 294919.57, 1],\n",
       "       [86419.7, 153514.11, 0.0, 2],\n",
       "       [76253.86, 113867.3, 298664.47, 0],\n",
       "       [78389.47, 153773.43, 299737.29, 2],\n",
       "       [73994.56, 122782.75, 303319.26, 1],\n",
       "       [67532.53, 105751.03, 304768.73, 1],\n",
       "       [77044.01, 99281.34, 140574.81, 2],\n",
       "       [64664.71, 139553.16, 137962.62, 0],\n",
       "       [75328.87, 144135.98, 134050.07, 1],\n",
       "       [72107.6, 127864.55, 353183.81, 2],\n",
       "       [66051.52, 182645.56, 118148.2, 1],\n",
       "       [65605.48, 153032.06, 107138.38, 2],\n",
       "       [61994.48, 115641.28, 91131.24, 1],\n",
       "       [61136.38, 152701.92, 88218.23, 2],\n",
       "       [63408.86, 129219.61, 46085.25, 0],\n",
       "       [55493.95, 103057.49, 214634.81, 1],\n",
       "       [46426.07, 157693.92, 210797.67, 0],\n",
       "       [46014.02, 85047.44, 205517.64, 2],\n",
       "       [28663.76, 127056.21, 201126.82, 1],\n",
       "       [44069.95, 51283.14, 197029.42, 0],\n",
       "       [20229.59, 65947.93, 185265.1, 2],\n",
       "       [38558.51, 82982.09, 174999.3, 0],\n",
       "       [28754.33, 118546.05, 172795.67, 0],\n",
       "       [27892.92, 84710.77, 164470.71, 1],\n",
       "       [23640.93, 96189.63, 148001.11, 0],\n",
       "       [15505.73, 127382.3, 35534.17, 2],\n",
       "       [22177.74, 154806.14, 28334.72, 0],\n",
       "       [1000.23, 124153.04, 1903.93, 2],\n",
       "       [1315.46, 115816.21, 297114.46, 1],\n",
       "       [0.0, 135426.92, 0.0, 0],\n",
       "       [542.05, 51743.15, 0.0, 2],\n",
       "       [0.0, 116983.8, 45173.06, 0]], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now applying OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder_X = OneHotEncoder(categorical_features = [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= onehotencoder_X.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.65349200e+05,   1.36897800e+05,   4.71784100e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.62597700e+05,   1.51377590e+05,   4.43898530e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.53441510e+05,   1.01145550e+05,   4.07934540e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.44372410e+05,   1.18671850e+05,   3.83199620e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.42107340e+05,   9.13917700e+04,   3.66168420e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.31876900e+05,   9.98147100e+04,   3.62861360e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.34615460e+05,   1.47198870e+05,   1.27716820e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.30298130e+05,   1.45530060e+05,   3.23876680e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.20542520e+05,   1.48718950e+05,   3.11613290e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.23334880e+05,   1.08679170e+05,   3.04981620e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.01913080e+05,   1.10594110e+05,   2.29160950e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00671960e+05,   9.17906100e+04,   2.49744550e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          9.38637500e+04,   1.27320380e+05,   2.49839440e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          9.19923900e+04,   1.35495070e+05,   2.52664930e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.19943240e+05,   1.56547420e+05,   2.56512920e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.14523610e+05,   1.22616840e+05,   2.61776230e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          7.80131100e+04,   1.21597550e+05,   2.64346060e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          9.46571600e+04,   1.45077580e+05,   2.82574310e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          9.17491600e+04,   1.14175790e+05,   2.94919570e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          8.64197000e+04,   1.53514110e+05,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          7.62538600e+04,   1.13867300e+05,   2.98664470e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.83894700e+04,   1.53773430e+05,   2.99737290e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          7.39945600e+04,   1.22782750e+05,   3.03319260e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.75325300e+04,   1.05751030e+05,   3.04768730e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.70440100e+04,   9.92813400e+04,   1.40574810e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.46647100e+04,   1.39553160e+05,   1.37962620e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          7.53288700e+04,   1.44135980e+05,   1.34050070e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.21076000e+04,   1.27864550e+05,   3.53183810e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.60515200e+04,   1.82645560e+05,   1.18148200e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          6.56054800e+04,   1.53032060e+05,   1.07138380e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.19944800e+04,   1.15641280e+05,   9.11312400e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          6.11363800e+04,   1.52701920e+05,   8.82182300e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.34088600e+04,   1.29219610e+05,   4.60852500e+04],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          5.54939500e+04,   1.03057490e+05,   2.14634810e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.64260700e+04,   1.57693920e+05,   2.10797670e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          4.60140200e+04,   8.50474400e+04,   2.05517640e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.86637600e+04,   1.27056210e+05,   2.01126820e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.40699500e+04,   5.12831400e+04,   1.97029420e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          2.02295900e+04,   6.59479300e+04,   1.85265100e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.85585100e+04,   8.29820900e+04,   1.74999300e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.87543300e+04,   1.18546050e+05,   1.72795670e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.78929200e+04,   8.47107700e+04,   1.64470710e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.36409300e+04,   9.61896300e+04,   1.48001110e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.55057300e+04,   1.27382300e+05,   3.55341700e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.21777400e+04,   1.54806140e+05,   2.83347200e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00023000e+03,   1.24153040e+05,   1.90393000e+03],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.31546000e+03,   1.15816210e+05,   2.97114460e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.35426920e+05,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          5.42050000e+02,   5.17431500e+04,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.16983800e+05,   4.51730600e+04]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing all the one hot encoded - state columns\n",
    "X[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Avoding the dummy variable trap\n",
    "X = X[:,1:] #Manually doing it but generally algorithm will take care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   1.00000000e+00,   1.65349200e+05,\n",
       "          1.36897800e+05,   4.71784100e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.62597700e+05,\n",
       "          1.51377590e+05,   4.43898530e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.53441510e+05,\n",
       "          1.01145550e+05,   4.07934540e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.44372410e+05,\n",
       "          1.18671850e+05,   3.83199620e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.42107340e+05,\n",
       "          9.13917700e+04,   3.66168420e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.31876900e+05,\n",
       "          9.98147100e+04,   3.62861360e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.34615460e+05,\n",
       "          1.47198870e+05,   1.27716820e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.30298130e+05,\n",
       "          1.45530060e+05,   3.23876680e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.20542520e+05,\n",
       "          1.48718950e+05,   3.11613290e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.23334880e+05,\n",
       "          1.08679170e+05,   3.04981620e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.01913080e+05,\n",
       "          1.10594110e+05,   2.29160950e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00671960e+05,\n",
       "          9.17906100e+04,   2.49744550e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   9.38637500e+04,\n",
       "          1.27320380e+05,   2.49839440e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   9.19923900e+04,\n",
       "          1.35495070e+05,   2.52664930e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.19943240e+05,\n",
       "          1.56547420e+05,   2.56512920e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.14523610e+05,\n",
       "          1.22616840e+05,   2.61776230e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.80131100e+04,\n",
       "          1.21597550e+05,   2.64346060e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   9.46571600e+04,\n",
       "          1.45077580e+05,   2.82574310e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   9.17491600e+04,\n",
       "          1.14175790e+05,   2.94919570e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   8.64197000e+04,\n",
       "          1.53514110e+05,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.62538600e+04,\n",
       "          1.13867300e+05,   2.98664470e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   7.83894700e+04,\n",
       "          1.53773430e+05,   2.99737290e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   7.39945600e+04,\n",
       "          1.22782750e+05,   3.03319260e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   6.75325300e+04,\n",
       "          1.05751030e+05,   3.04768730e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   7.70440100e+04,\n",
       "          9.92813400e+04,   1.40574810e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   6.46647100e+04,\n",
       "          1.39553160e+05,   1.37962620e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   7.53288700e+04,\n",
       "          1.44135980e+05,   1.34050070e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   7.21076000e+04,\n",
       "          1.27864550e+05,   3.53183810e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   6.60515200e+04,\n",
       "          1.82645560e+05,   1.18148200e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   6.56054800e+04,\n",
       "          1.53032060e+05,   1.07138380e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   6.19944800e+04,\n",
       "          1.15641280e+05,   9.11312400e+04],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   6.11363800e+04,\n",
       "          1.52701920e+05,   8.82182300e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   6.34088600e+04,\n",
       "          1.29219610e+05,   4.60852500e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   5.54939500e+04,\n",
       "          1.03057490e+05,   2.14634810e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   4.64260700e+04,\n",
       "          1.57693920e+05,   2.10797670e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   4.60140200e+04,\n",
       "          8.50474400e+04,   2.05517640e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   2.86637600e+04,\n",
       "          1.27056210e+05,   2.01126820e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   4.40699500e+04,\n",
       "          5.12831400e+04,   1.97029420e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   2.02295900e+04,\n",
       "          6.59479300e+04,   1.85265100e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   3.85585100e+04,\n",
       "          8.29820900e+04,   1.74999300e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.87543300e+04,\n",
       "          1.18546050e+05,   1.72795670e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   2.78929200e+04,\n",
       "          8.47107700e+04,   1.64470710e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.36409300e+04,\n",
       "          9.61896300e+04,   1.48001110e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.55057300e+04,\n",
       "          1.27382300e+05,   3.55341700e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.21777400e+04,\n",
       "          1.54806140e+05,   2.83347200e+04],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00023000e+03,\n",
       "          1.24153040e+05,   1.90393000e+03],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.31546000e+03,\n",
       "          1.15816210e+05,   2.97114460e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.35426920e+05,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   5.42050000e+02,\n",
       "          5.17431500e+04,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.16983800e+05,   4.51730600e+04]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.00000000e+00,   0.00000000e+00,   5.54939500e+04,\n",
       "           1.03057490e+05,   2.14634810e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   4.60140200e+04,\n",
       "           8.50474400e+04,   2.05517640e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   7.53288700e+04,\n",
       "           1.44135980e+05,   1.34050070e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   4.64260700e+04,\n",
       "           1.57693920e+05,   2.10797670e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   9.17491600e+04,\n",
       "           1.14175790e+05,   2.94919570e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.30298130e+05,\n",
       "           1.45530060e+05,   3.23876680e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.19943240e+05,\n",
       "           1.56547420e+05,   2.56512920e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.00023000e+03,\n",
       "           1.24153040e+05,   1.90393000e+03],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   5.42050000e+02,\n",
       "           5.17431500e+04,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   6.56054800e+04,\n",
       "           1.53032060e+05,   1.07138380e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.14523610e+05,\n",
       "           1.22616840e+05,   2.61776230e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   6.19944800e+04,\n",
       "           1.15641280e+05,   9.11312400e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   6.34088600e+04,\n",
       "           1.29219610e+05,   4.60852500e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   7.80131100e+04,\n",
       "           1.21597550e+05,   2.64346060e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   2.36409300e+04,\n",
       "           9.61896300e+04,   1.48001110e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   7.62538600e+04,\n",
       "           1.13867300e+05,   2.98664470e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.55057300e+04,\n",
       "           1.27382300e+05,   3.55341700e+04],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.20542520e+05,\n",
       "           1.48718950e+05,   3.11613290e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   9.19923900e+04,\n",
       "           1.35495070e+05,   2.52664930e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   6.46647100e+04,\n",
       "           1.39553160e+05,   1.37962620e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.31876900e+05,\n",
       "           9.98147100e+04,   3.62861360e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   9.46571600e+04,\n",
       "           1.45077580e+05,   2.82574310e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   2.87543300e+04,\n",
       "           1.18546050e+05,   1.72795670e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.16983800e+05,   4.51730600e+04],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.62597700e+05,\n",
       "           1.51377590e+05,   4.43898530e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   9.38637500e+04,\n",
       "           1.27320380e+05,   2.49839440e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   4.40699500e+04,\n",
       "           5.12831400e+04,   1.97029420e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   7.70440100e+04,\n",
       "           9.92813400e+04,   1.40574810e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.34615460e+05,\n",
       "           1.47198870e+05,   1.27716820e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   6.75325300e+04,\n",
       "           1.05751030e+05,   3.04768730e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   2.86637600e+04,\n",
       "           1.27056210e+05,   2.01126820e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   7.83894700e+04,\n",
       "           1.53773430e+05,   2.99737290e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   8.64197000e+04,\n",
       "           1.53514110e+05,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.23334880e+05,\n",
       "           1.08679170e+05,   3.04981620e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   3.85585100e+04,\n",
       "           8.29820900e+04,   1.74999300e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.31546000e+03,\n",
       "           1.15816210e+05,   2.97114460e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.44372410e+05,\n",
       "           1.18671850e+05,   3.83199620e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.65349200e+05,\n",
       "           1.36897800e+05,   4.71784100e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.35426920e+05,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   2.21777400e+04,\n",
       "           1.54806140e+05,   2.83347200e+04]]),\n",
       " array([[  1.00000000e+00,   0.00000000e+00,   6.60515200e+04,\n",
       "           1.82645560e+05,   1.18148200e+05],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   1.00671960e+05,\n",
       "           9.17906100e+04,   2.49744550e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.01913080e+05,\n",
       "           1.10594110e+05,   2.29160950e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   2.78929200e+04,\n",
       "           8.47107700e+04,   1.64470710e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.53441510e+05,\n",
       "           1.01145550e+05,   4.07934540e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   7.21076000e+04,\n",
       "           1.27864550e+05,   3.53183810e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   2.02295900e+04,\n",
       "           6.59479300e+04,   1.85265100e+05],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   6.11363800e+04,\n",
       "           1.52701920e+05,   8.82182300e+04],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   7.39945600e+04,\n",
       "           1.22782750e+05,   3.03319260e+05],\n",
       "        [  1.00000000e+00,   0.00000000e+00,   1.42107340e+05,\n",
       "           9.13917700e+04,   3.66168420e+05]]),\n",
       " array([  96778.92,   96479.51,  105733.54,   96712.8 ,  124266.9 ,\n",
       "         155752.6 ,  132602.65,   64926.08,   35673.41,  101004.64,\n",
       "         129917.04,   99937.59,   97427.84,  126992.93,   71498.49,\n",
       "         118474.03,   69758.98,  152211.77,  134307.35,  107404.34,\n",
       "         156991.12,  125370.37,   78239.91,   14681.4 ,  191792.06,\n",
       "         141585.52,   89949.14,  108552.04,  156122.51,  108733.99,\n",
       "          90708.19,  111313.02,  122776.86,  149759.96,   81005.76,\n",
       "          49490.75,  182901.99,  192261.83,   42559.73,   65200.33]),\n",
       " array([ 103282.38,  144259.4 ,  146121.95,   77798.83,  191050.39,\n",
       "         105008.31,   81229.06,   97483.56,  110352.25,  166187.94]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we need to do feature scaling - Library will take care it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying the Multiple Linear Regression algorithm now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 103015.20159795,  132582.27760817,  132447.73845176,\n",
       "          71976.09851257,  178537.48221058,  116161.24230165,\n",
       "          67851.69209675,   98791.73374686,  113969.43533013,\n",
       "         167921.06569553]),\n",
       " array([ 103282.38,  144259.4 ,  146121.95,   77798.83,  191050.39,\n",
       "         105008.31,   81229.06,   97483.56,  110352.25,  166187.94]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2fc5ea9a20>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(y_pred, y_test, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFDCAYAAAB/UdRdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2fc49abcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFDCAYAAAB/UdRdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2fc5dc8208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFCCAYAAAAOro+YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2fc5dd9a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -267.17840205, -11677.12239183, -13674.21154824,  -5822.73148743,\n",
       "       -12512.90778942,  11152.93230165, -13377.36790325,   1308.17374686,\n",
       "         3617.18533013,   1733.12569553])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "# to enable b0*x0 we are going to add a column of 1s that replaces X0\n",
    "\n",
    "X = np.append(arr=np.ones((50,1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proof that 1s got added.\n",
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,1,2,3,4,5]] # taking all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.65349200e+05,   1.36897800e+05,   4.71784100e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.62597700e+05,   1.51377590e+05,   4.43898530e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.53441510e+05,   1.01145550e+05,   4.07934540e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.44372410e+05,   1.18671850e+05,   3.83199620e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.42107340e+05,   9.13917700e+04,   3.66168420e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.31876900e+05,   9.98147100e+04,   3.62861360e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.34615460e+05,   1.47198870e+05,   1.27716820e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.30298130e+05,   1.45530060e+05,   3.23876680e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.20542520e+05,   1.48718950e+05,   3.11613290e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.23334880e+05,   1.08679170e+05,   3.04981620e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.01913080e+05,   1.10594110e+05,   2.29160950e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00671960e+05,   9.17906100e+04,   2.49744550e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          9.38637500e+04,   1.27320380e+05,   2.49839440e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          9.19923900e+04,   1.35495070e+05,   2.52664930e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.19943240e+05,   1.56547420e+05,   2.56512920e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.14523610e+05,   1.22616840e+05,   2.61776230e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          7.80131100e+04,   1.21597550e+05,   2.64346060e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          9.46571600e+04,   1.45077580e+05,   2.82574310e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          9.17491600e+04,   1.14175790e+05,   2.94919570e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          8.64197000e+04,   1.53514110e+05,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          7.62538600e+04,   1.13867300e+05,   2.98664470e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.83894700e+04,   1.53773430e+05,   2.99737290e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          7.39945600e+04,   1.22782750e+05,   3.03319260e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.75325300e+04,   1.05751030e+05,   3.04768730e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.70440100e+04,   9.92813400e+04,   1.40574810e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.46647100e+04,   1.39553160e+05,   1.37962620e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          7.53288700e+04,   1.44135980e+05,   1.34050070e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.21076000e+04,   1.27864550e+05,   3.53183810e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.60515200e+04,   1.82645560e+05,   1.18148200e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          6.56054800e+04,   1.53032060e+05,   1.07138380e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.19944800e+04,   1.15641280e+05,   9.11312400e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          6.11363800e+04,   1.52701920e+05,   8.82182300e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.34088600e+04,   1.29219610e+05,   4.60852500e+04],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          5.54939500e+04,   1.03057490e+05,   2.14634810e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.64260700e+04,   1.57693920e+05,   2.10797670e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          4.60140200e+04,   8.50474400e+04,   2.05517640e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.86637600e+04,   1.27056210e+05,   2.01126820e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.40699500e+04,   5.12831400e+04,   1.97029420e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          2.02295900e+04,   6.59479300e+04,   1.85265100e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.85585100e+04,   8.29820900e+04,   1.74999300e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.87543300e+04,   1.18546050e+05,   1.72795670e+05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.78929200e+04,   8.47107700e+04,   1.64470710e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.36409300e+04,   9.61896300e+04,   1.48001110e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.55057300e+04,   1.27382300e+05,   3.55341700e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.21777400e+04,   1.54806140e+05,   2.83347200e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00023000e+03,   1.24153040e+05,   1.90393000e+03],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.31546000e+03,   1.15816210e+05,   2.97114460e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.35426920e+05,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          5.42050000e+02,   5.17431500e+04,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.16983800e+05,   4.51730600e+04]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a new regressor using the statsmodel.\n",
    "# ols is Ordinary Least Squares\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the statistical summary that gives us the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:40:16</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04   6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030  6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003  6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712     0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132     0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008     0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Sun, 22 Dec 2019   Prob (F-statistic):           1.34e-27\n",
       "Time:                        17:40:16   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000      3.62e+04   6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953     -6595.030  6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990     -6604.003  6520.229\n",
       "x3             0.8060      0.046     17.369      0.000         0.712     0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608        -0.132     0.078\n",
       "x5             0.0270      0.017      1.574      0.123        -0.008     0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lower the P-value (probability), the more the independent variable is significant with respect to dependent variable.\n",
    "# Also P-value is the probability of getting a sample like ours. i.e., Higher the P-value it is pretty obvious that our sample is\n",
    "# not strange. Lesser the P-value, the data is strange when we consider the Null hypothesis is true.\n",
    "\n",
    "# from the summary table above (regressor_OLS.summary())\n",
    "# Higher the P-value - Data isn't strange - No significance of independent variable in determining dependent variable.\n",
    "# Lesser the P-value - Data is strange - Significane of independent variable in determining dependent variable.\n",
    "\n",
    "# Refer notes - Peanuts in a chocolate bar example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:50:20</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04  6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821  6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714     0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131     0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007     0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Sun, 22 Dec 2019   Prob (F-statistic):           8.49e-29\n",
       "Time:                        17:50:20   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000      3.67e+04  6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940     -5621.821  6062.138\n",
       "x2             0.8060      0.046     17.606      0.000         0.714     0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604        -0.131     0.077\n",
       "x4             0.0270      0.017      1.592      0.118        -0.007     0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from above, we can remove the x2 (dummy variable for state)\n",
    "X_opt = X[:,[0,1,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:51:10</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04  6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715     0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130     0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006     0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Sun, 22 Dec 2019   Prob (F-statistic):           4.53e-30\n",
       "Time:                        17:51:10   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000      3.69e+04  6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000         0.715     0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602        -0.130     0.076\n",
       "x3             0.0272      0.016      1.655      0.105        -0.006     0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from above, we can remove the x2 (dummy variable for state)\n",
    "X_opt = X[:,[0,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:56:08</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04  5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713     0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001     0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Sun, 22 Dec 2019   Prob (F-statistic):           2.16e-31\n",
       "Time:                        17:56:08   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000      4.16e+04  5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000         0.713     0.880\n",
       "x2             0.0299      0.016      1.927      0.060        -0.001     0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this moment both the dummy variables for state has no significance due to high P-value\n",
    "# from above, we can remove the Administration column as P value is 0.602\n",
    "X_opt = X[:,[0,3,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   60.88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>4.38e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:58:32</td>     <th>  Log-Likelihood:    </th> <td> -580.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1164.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1168.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>     6e+04</td> <td> 7684.530</td> <td>    7.808</td> <td> 0.000</td> <td> 4.46e+04  7.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.2465</td> <td>    0.032</td> <td>    7.803</td> <td> 0.000</td> <td>    0.183     0.310</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.420</td> <th>  Durbin-Watson:     </th> <td>   1.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.110</td> <th>  Jarque-Bera (JB):  </th> <td>   3.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.336</td> <th>  Prob(JB):          </th> <td>   0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.188</td> <th>  Cond. No.          </th> <td>4.89e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.559\n",
       "Model:                            OLS   Adj. R-squared:                  0.550\n",
       "Method:                 Least Squares   F-statistic:                     60.88\n",
       "Date:                Sun, 22 Dec 2019   Prob (F-statistic):           4.38e-10\n",
       "Time:                        17:58:32   Log-Likelihood:                -580.18\n",
       "No. Observations:                  50   AIC:                             1164.\n",
       "Df Residuals:                      48   BIC:                             1168.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const           6e+04   7684.530      7.808      0.000      4.46e+04  7.55e+04\n",
       "x1             0.2465      0.032      7.803      0.000         0.183     0.310\n",
       "==============================================================================\n",
       "Omnibus:                        4.420   Durbin-Watson:                   1.178\n",
       "Prob(Omnibus):                  0.110   Jarque-Bera (JB):                3.882\n",
       "Skew:                          -0.336   Prob(JB):                        0.144\n",
       "Kurtosis:                       4.188   Cond. No.                     4.89e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.89e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this moment,\n",
    "# const - for X0\n",
    "# X1 - R&D Spend, X2 - Marketing spend\n",
    "# Here, X2 - Marketing spend is slightly significant as P > SL i.e., 0.06 > 0.05\n",
    "X_opt = X[:,[0,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from the table above, the conclustion is R&D spend has given the highest significance.\n",
    "# We couls also use R-squared and adjusted R-square to determine which have more significance on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very Important - Automatic Backward Elimination"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Backward Elimination with p-values only:\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "def backwardElimination(x, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)\n",
    "\n",
    "# Backward Elimination with p-values and Adjusted R Squared:\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "def backwardElimination(x, SL):\n",
    "    numVars = len(x[0])\n",
    "    temp = np.zeros((50,6)).astype(int)\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
    "        if maxVar > SL:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    temp[:,j] = x[:, j]\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    tmp_regressor = sm.OLS(y, x).fit()\n",
    "                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
    "                    if (adjR_before >= adjR_after):\n",
    "                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "                        print (regressor_OLS.summary())\n",
    "                        return x_rollback\n",
    "                    else:\n",
    "                        continue\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
